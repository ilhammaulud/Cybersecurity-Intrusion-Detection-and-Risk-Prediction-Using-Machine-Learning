Conceptual Problems

Jawab pertanyaan berikut:

1. Jelaskan latar belakang adanya bagging dan cara kerja bagging !

Bagging (Bootstrap Aggregating) muncul untuk mengurangi variansi model machine learning, 
terutama untuk model yang sensitif terhadap data training seperti Decision Tree.

Latar belakang: Model seperti decision tree cenderung overfitting pada dataset training karena sangat mengikuti data yang tersedia.
Bagging membantu dengan membuat beberapa model dari subset data yang berbeda (bootstrap samples) sehingga prediksi akhir lebih stabil.

Cara kerja:
Ambil beberapa subset data secara acak dengan pengembalian (bootstrap sampling).
Latih model yang sama pada setiap subset data.
Gabungkan hasil prediksi dari semua model (misal rata-rata untuk regresi atau voting mayoritas untuk klasifikasi).

2. Jelaskan perbedaan cara kerja algoritma Random Forest dengan algoritma boosting yang Anda pilih !

* Random Forest
Merupakan metode bagging yang membangun banyak decision tree.
Setiap tree dilatih secara independen menggunakan subset data dan subset fitur.
Prediksi akhir diambil melalui voting mayoritas (klasifikasi) atau rata-rata (regresi).

Fokus utama: mengurangi variansi.

* Boosting
Metode ensemble yang membangun model secara berurutan.
Setiap model baru berfokus pada kesalahan yang dibuat oleh model sebelumnya.
Prediksi akhir diperoleh dengan kombinasi bertingkat dari semua model, biasanya dengan bobot tertentu.

Fokus utama: mengurangi bias sekaligus variansi, menghasilkan model yang lebih akurat tetapi berpotensi overfit jika tidak dikontrol.

3. Jelaskan apa yang dimaksud dengan Cross Validation !
Cross Validation (CV) adalah metode untuk mengevaluasi performa model dengan cara membagi dataset menjadi beberapa bagian (folds)
dan melatih serta menguji model secara bergantian.
Contohnya, 5-Fold Cross Validation: dataset dibagi menjadi 5 bagian, 4 bagian untuk training dan 1 bagian untuk testing, 
kemudian diulang sampai setiap bagian menjadi testing sekali.

Tujuan: memastikan model tidak overfitting dan performa yang diukur lebih stabil dan representatif terhadap data baru.